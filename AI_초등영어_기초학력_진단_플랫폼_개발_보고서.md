# Ⅲ. AI 초등영어 기초학력 진단 플랫폼 개발

**작성자**: 김민제  
**작성일**: 2025년 1월  
**버전**: 1.0

---

## 1. 진단 플랫폼 개발 개요

### 1.1 플랫폼 개요

AI 초등영어 기초학력 진단 플랫폼(AIDTPEL: AI-based Diagnostic Test for Primary English Literacy)은 국가기초학력지원센터에서 설정한 초등학교 3~4학년군 영어과 최소한의 성취기준(이해)을 바탕으로 구축된 AI 기반 영어 읽기 능력 진단 평가 시스템입니다. 

본 플랫폼은 인공지능 기술을 활용하여 학생들의 영어 읽기 능력을 자동으로 평가하고 분석하며, 교사가 학생들의 학습 진도를 체계적으로 관리할 수 있도록 지원합니다. 특히 비영어권(EFL) 환경인 한국의 교육 현실에 최적화되어, 학생들의 발음 특성을 반영한 정확한 평가가 가능합니다.

#### 시스템 전체 개요 다이어그램

```mermaid
graph TB
    subgraph "사용자 계층"
        A[학생] --> B[웹 브라우저]
        C[교사] --> B
    end
    
    subgraph "애플리케이션 계층"
        B --> D[Next.js 웹 애플리케이션<br/>Vercel 배포]
    end
    
    subgraph "서비스 계층"
        D --> E[Supabase 인증]
        D --> F[Supabase 데이터베이스]
        D --> G[Supabase 스토리지]
        D --> H[OpenAI API]
    end
    
    subgraph "데이터 저장소"
        F --> I[(test_results 테이블)]
        F --> J[(user_profiles 테이블)]
        G --> K[음성 파일 저장소]
        H --> L[GPT-4o-transcribe 음성 인식]
        H --> M[GPT-4o 자동 채점]
    end
    
    style A fill:#e1f5ff
    style C fill:#fff4e1
    style D fill:#e8f5e9
    style H fill:#f3e5f5
```

**그림 1. 시스템 전체 구조도**

시스템은 사용자 계층, 애플리케이션 계층, 서비스 계층, 데이터 저장소로 구성되어 있습니다. 학생과 교사는 웹 브라우저를 통해 플랫폼에 접근하며, Next.js 기반 웹 애플리케이션이 모든 요청을 처리합니다. Supabase는 인증, 데이터베이스, 스토리지 서비스를 제공하고, OpenAI API는 음성 인식 및 자동 채점 기능을 담당합니다.

### 1.2 개발 배경 및 목적

#### 1.2.1 개발 배경

기존 영어 읽기 평가 방식은 다음과 같은 한계를 가지고 있었습니다:

1. **시간 소모**: 교사가 일일이 학생의 발음을 듣고 평가해야 하며, 학생당 15~20분의 시간이 소요됩니다.
2. **일관성 부족**: 교사의 주관적 판단과 피로도에 따라 평가 결과가 달라질 수 있습니다.
3. **진도 추적 어려움**: 엑셀 수기 입력이나 수동 분석에 많은 시간이 소요됩니다.
4. **EFL 환경 미최적화**: 기존 평가 도구들은 원어민 발음 기준으로 설계되어 한국 학생들에게 부적합합니다.

#### 1.2.2 개발 목적

본 플랫폼은 다음과 같은 목적을 가지고 개발되었습니다:

1. **자동화된 평가 시스템 구축**: AI 음성 인식 및 자동 채점을 통해 평가 시간을 90% 이상 단축합니다.
2. **객관적이고 일관된 평가**: AI 기반 평가로 주관성을 제거하고 일관된 평가 결과를 제공합니다.
3. **효율적인 학습 진도 관리**: 교사 대시보드를 통해 모든 학생의 평가 결과를 한눈에 확인하고 분석할 수 있습니다.
4. **EFL 환경 최적화**: 한국 학생들의 발음 특성을 반영한 평가 시스템을 구현합니다.

### 1.3 평가 기준

본 플랫폼은 **국가기초학력지원센터에서 설정한 초등학교 3~4학년군 영어과 최소한의 성취기준(이해)**을 바탕으로 개발되었습니다. 

6가지 최소 성취기준은 다음과 같이 단계적으로 구성되어 있습니다:

1. **알파벳 이름 말하기**: 알파벳 대소문자 인식 능력
2. **음소 분리**: 최소대립쌍을 통한 음소 구분 능력
3. **강세 및 리듬 패턴**: 단어의 강세와 리듬 인식 능력
4. **파닉스 읽기**: 파닉스 규칙 적용 및 읽기 유창성
5. **의미 이해**: 단어, 어구, 문장의 의미 파악 능력
6. **주요 정보 파악**: 듣기/읽기 내용의 핵심 정보 이해 능력

### 1.4 개발 절차

플랫폼 개발은 다음과 같은 단계로 진행되었습니다:

```mermaid
graph LR
    A[1단계<br/>요구사항 분석] --> B[2단계<br/>시스템 설계]
    B --> C[3단계<br/>프로토타입 개발]
    C --> D[4단계<br/>AI 평가 모듈 개발]
    D --> E[5단계<br/>교사 대시보드 개발]
    E --> F[6단계<br/>테스트 및 최적화]
    F --> G[7단계<br/>배포 및 운영]
    
    style A fill:#e3f2fd
    style B fill:#e8f5e9
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style E fill:#e0f2f1
    style F fill:#fce4ec
    style G fill:#e1f5fe
```

**그림 2. 개발 절차 단계별 프로세스**

#### 1.4.1 1단계: 요구사항 분석 (2025년 10월 초)

- 교육 현장의 평가 문제점 조사 및 분석
- 국가기초학력지원센터 최소 성취기준 검토
- 사용자(학생, 교사) 니즈 파악
- 기술 요구사항 정의

#### 1.4.2 2단계: 시스템 설계 (2025년 10월 중순)

- 시스템 아키텍처 설계
- 데이터베이스 스키마 설계
- API 엔드포인트 설계
- 사용자 인터페이스(UI/UX) 디자인

#### 1.4.3 3단계: 프로토타입 개발 (2025년 10월 중순~말)

- Next.js 프로젝트 초기 설정
- 기본 인증 시스템 구축
- 6가지 평가 유형 기본 구조 구현
- 음성 녹음 기능 구현

#### 1.4.4 4단계: AI 평가 모듈 개발 (2025년 10월 말~11월 초)

- OpenAI Whisper API 연동 (음성 인식)
- GPT-4o API 연동 (자동 채점)
- 평가 유형별 채점 로직 구현
- EFL 환경 최적화 (한국 발음 보정)

#### 1.4.5 5단계: 교사 대시보드 개발 (2025년 11월 중순)

- 교사 관리 시스템 구축
- 학생-교사 관계 매핑
- 통계 및 차트 시각화
- AI 기반 종합 평가 코멘트 생성

#### 1.4.6 6단계: 테스트 및 최적화 (2025년 11월 말)

- 기능 테스트
- 성능 최적화
- 보안 검증 (RLS 정책 확인)
- 사용자 피드백 수집 및 반영

#### 1.4.7 7단계: 배포 및 운영 (2025년 12월~)

- Vercel 배포
- 운영 모니터링
- 지속적인 기능 개선

### 1.5 기술 선택 근거

#### 1.5.1 프론트엔드 기술 스택

**Next.js 15 + React 19 + TypeScript**
- **선택 근거**: 
  - 서버 사이드 렌더링(SSR)을 통한 빠른 초기 로딩 속도
  - 서버 컴포넌트를 활용한 성능 최적화
  - 타입 안정성을 통한 개발 생산성 향상
  - 풍부한 생태계와 커뮤니티 지원

#### 1.5.2 백엔드 및 데이터베이스

**Next.js API Routes + Supabase**
- **선택 근거**:
  - 서버리스 아키텍처로 확장성 및 비용 효율성 확보
  - Supabase의 PostgreSQL 데이터베이스는 복잡한 쿼리 및 관계형 데이터 관리에 적합
  - Row Level Security(RLS)를 통한 보안 강화
  - 인증, 스토리지 등 통합 서비스 제공

#### 1.5.3 AI 기술

**OpenAI GPT-4o-transcribe + GPT-4o**
- **선택 근거**:
  - GPT-4o-transcribe는 기존 Whisper 모델을 뛰어넘는 정확도와 성능을 제공하며, 특히 GPT-4o의 언어 이해 능력을 바탕으로 문맥을 파악하여 더 정교한 전사를 수행
  - GPT-4o는 맥락을 이해한 지능형 채점 가능
  - 다국어 지원으로 한국 발음 혼합 응답 처리 가능
  - 안정적인 API 서비스 제공
  - 프롬프트 매개변수를 활용하여 추가적인 맥락 제공 가능

#### 1.5.4 프론트엔드 음성 녹음 기술

**MediaRecorder API + WebM 형식**
- **선택 근거**:
  - 브라우저 네이티브 API로 추가 라이브러리 불필요
  - WebM 형식(audio/webm;codecs=opus)은 고품질 오디오 압축 제공
  - 실시간 음성 캡처 및 Blob 생성 가능
  - React Hooks(useState, useEffect, useRef, useCallback)를 활용한 효율적인 상태 관리

#### 1.5.5 배포 및 인프라

**Vercel**
- **선택 근거**:
  - Next.js와의 완벽한 통합
  - 자동 배포 및 스케일링
  - 글로벌 CDN을 통한 빠른 콘텐츠 전송
  - 개발자 친화적인 배포 프로세스

---

## 2. 진단 플랫폼 체계 및 구성 요소

### 2.1 플랫폼 전체 체계

본 플랫폼은 크게 **평가 모듈**, **AI 평가 시스템**, **교사 관리 시스템**, **데이터 관리 시스템**으로 구성되어 있습니다.

#### 시스템 아키텍처 다이어그램

```mermaid
graph TB
    subgraph "사용자 인터페이스"
        A[학생 인터페이스]
        B[교사 대시보드]
    end
    
    subgraph "평가 모듈"
        C[1교시: 알파벳]
        D[2교시: 음소 분리]
        E[3교시: 강세/리듬]
        F[4교시: 파닉스]
        G[5교시: 어휘]
        H[6교시: 이해력]
    end
    
    subgraph "AI 평가 시스템"
        I[음성 녹음]
        J[OpenAI Whisper<br/>음성 인식]
        K[GPT-4o<br/>자동 채점]
        L[피드백 생성]
    end
    
    subgraph "데이터 관리"
        M[Supabase<br/>데이터베이스]
        N[Supabase<br/>스토리지]
        O[결과 분석]
    end
    
    A --> C
    A --> D
    A --> E
    A --> F
    A --> G
    A --> H
    
    C --> I
    D --> I
    E --> I
    F --> I
    G --> I
    H --> I
    
    I --> J
    J --> K
    K --> L
    
    K --> M
    I --> N
    M --> O
    
    B --> O
    O --> B
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style I fill:#f3e5f5
    style J fill:#f3e5f5
    style K fill:#f3e5f5
    style M fill:#e8f5e9
```

**그림 3. 플랫폼 시스템 아키텍처**

플랫폼은 사용자가 평가를 진행하면, 음성 데이터를 수집하고 AI 시스템이 자동으로 인식 및 채점한 후, 결과를 데이터베이스에 저장합니다. 교사는 대시보드를 통해 저장된 데이터를 분석하고 학생들의 학습 진도를 확인할 수 있습니다.

### 2.2 데이터 흐름

#### 평가 프로세스 데이터 흐름도

```mermaid
sequenceDiagram
    participant S as 학생
    participant UI as 웹 인터페이스
    participant API as API 서버
    participant ST as Supabase Storage
    participant OAI as OpenAI API
    participant DB as Supabase DB
    
    S->>UI: 평가 시작 (음성 녹음)
    UI->>S: 실시간 음성 캡처
    S->>UI: 평가 완료 (음성 파일)
    UI->>ST: 음성 파일 업로드
    ST-->>API: 업로드 완료 (URL)
    UI->>API: 평가 제출 요청
    
    API->>OAI: 음성 파일 전송 (Whisper)
    OAI-->>API: 음성 전사 결과
    
    API->>OAI: 전사 결과 + 평가 기준 (GPT-4o)
    OAI-->>API: 채점 결과 + 피드백
    
    API->>DB: 결과 저장
    DB-->>API: 저장 완료
    API-->>UI: 평가 결과 반환
    UI-->>S: 결과 표시
```

**그림 4. 평가 프로세스 데이터 흐름**

학생이 평가를 완료하면 평가 유형에 따라 다음과 같이 처리됩니다:

- **음성 평가 (1교시, 4교시)**: 
  - 음성 파일이 Supabase Storage에 업로드
  - OpenAI GPT-4o-transcribe API를 통해 음성이 텍스트로 전사 (타임라인 정보 포함)
  - 전사 결과와 타임라인을 GPT-4o에 전달하여 채점
  - 결과는 데이터베이스에 저장되어 즉시 학생에게 반환

- **선택형 평가 (2교시, 3교시, 5교시, 6교시)**:
  - 선택한 답안과 정답을 즉시 비교하여 채점
  - 결과는 데이터베이스에 저장되어 즉시 학생에게 반환

### 2.3 구성 요소 상세

#### 2.3.1 6가지 최소 성취기준 평가 유형

본 플랫폼은 국가기초학력지원센터에서 설정한 초등학교 3~4학년군 영어과 최소한의 성취기준(이해)에 기반한 6가지 평가 유형을 제공합니다.

##### 1교시: 알파벳 이름 말하기 (Alphabet)

- **평가 목적**: 알파벳 대소문자 이름 인식 속도 및 정확도 평가
- **평가 방식**: 음성 녹음 (학생이 화면에 표시된 알파벳 이름을 읽음)
- **제한 시간**: 1분 (60초)
- **문항 구성**: 총 52개 알파벳 (대문자 26개, 소문자 26개)을 섞인 순서로 제시
- **평가 내용**: 
  - 알파벳 이름을 정확히 읽는 능력
  - 대소문자 구분 능력
  - 읽기 속도

##### 2교시: 음소 분리 (Segmental Phoneme)

- **평가 목적**: 비슷한 소리를 듣고 구분하는 능력 평가
- **평가 방식**: 듣기 + 선택 (두 단어 또는 알파벳 중 들려준 것 선택)
- **제한 시간**: 1분 (60초)
- **문항 구성**: 총 20개 최소대립쌍 (예: fine/five, big/pig) 또는 알파벳 쌍
- **평가 내용**:
  - 최소대립쌍(minimal pair)을 통한 음소 구분 능력
  - 한국인이 헷갈려하는 음가(b/v, b/p, p/f, r/l 등) 구분
- **채점 방식**: 즉시 채점 (정답과 선택 답안 비교)
- **시간 측정**: 평가 시작부터 답안 선택까지 소요 시간 기록 (초 단위)

##### 3교시: 강세 및 리듬 패턴 (Suprasegmental Phoneme)

- **평가 목적**: 단어의 강세 패턴을 듣고 선택하는 능력 평가
- **평가 방식**: 듣기 + 선택 (강세 위치 선택)
- **제한 시간**: 1분 (60초)
- **문항 구성**: 총 20개 단어 (2음절 이상)
- **평가 내용**:
  - 단어의 강세 위치 인식 (예: APple, banANa)
  - 영어의 리듬 패턴 이해
- **채점 방식**: 즉시 채점 (정답과 선택 답안 비교)
- **시간 측정**: 평가 시작부터 답안 선택까지 소요 시간 기록 (초 단위)

##### 4교시: 파닉스 읽기 (Phonics)

- **평가 목적**: 파닉스 규칙 적용 및 읽기 유창성 평가
- **평가 방식**: 음성 녹음 (학생이 읽음)
- **제한 시간**: 1분 (60초)
- **문항 구성**: 3단계로 구성
  1. NWF (Nonsense Word Fluency): 무의미 단어 5개
  2. WRF (Word Reading Fluency): 실제 단어 5개
  3. ORF (Oral Reading Fluency): 문장 5개
- **평가 내용**:
  - 파닉스 규칙 적용 능력
  - 단어 읽기 유창성
  - 문장 읽기 유창성

##### 5교시: 의미 이해 (Vocabulary)

- **평가 목적**: 단어, 어구, 문장의 의미를 그림으로 선택하는 능력 평가
- **평가 방식**: 듣기/읽기 + 선택 (그림 선택)
- **제한 시간**: 1분 (60초)
- **문항 구성**: 동적 생성 (단어 → 어구 → 문장 순서로 순환 출제)
- **평가 내용**:
  - 단어 의미 이해
  - 어구 의미 이해
  - 문장 의미 이해
- **데이터 출처**: 천재교과서(함) - vocabulary_level.json, core_expressions.json
- **채점 방식**: 즉시 채점 (정답과 선택 답안 비교)
- **시간 측정**: 평가 시작부터 답안 선택까지 소요 시간 기록 (초 단위)
- **이미지 생성**: OpenAI DALL-E API를 활용한 문항별 맞춤 이미지 생성

##### 6교시: 주요 정보 파악 (Comprehension)

- **평가 목적**: 말이나 대화를 듣고/읽고 한국어 질문에 맞는 답을 이미지로 선택하는 능력 평가
- **평가 방식**: 듣기/읽기 + 선택 (이미지 선택)
- **제한 시간**: 1분 (60초)
- **문항 구성**: 총 40개 문항 (말 또는 대화 형식)
- **평가 내용**:
  - 색깔과 크기 묘사 이해
  - 인물의 모습 묘사 이해
  - 주요 정보 파악 능력
- **채점 방식**: 즉시 채점 (정답과 선택 답안 비교)
- **시간 측정**: 평가 시작부터 답안 선택까지 소요 시간 기록 (초 단위)

#### 2.3.2 AI 평가 시스템

##### 음성 인식 모듈

- **기술**: OpenAI GPT-4o-transcribe API
- **정확도**: 95% 이상
- **지원 언어**: 영어 (한국어 발음 혼합 지원)
- **처리 시간**: 평균 10~15초
- **주요 기능**:
  - 음성 파일 전사 (WebM 형식 지원)
  - 프롬프트 매개변수를 통한 맥락 제공
  - 타임라인 정보 제공 (segments 배열)
  - 신뢰도(confidence) 정보 제공
  - 다국어 지원
- **음성 녹음 기술**:
  - MediaRecorder API를 활용한 브라우저 네이티브 녹음
  - WebM 형식 (audio/webm;codecs=opus)으로 고품질 압축
  - 최대 5초 자동 녹음 또는 사용자 수동 중지
  - 실시간 오디오 청크 수집 및 Blob 생성

##### 자동 채점 모듈

- **기술**: OpenAI GPT-4o API
- **주요 기능**:
  - 문항별 정답/오답 판정
  - 정확도 계산 (0~100%)
  - 상세 피드백 생성
  - 종합 평가 코멘트 작성
- **처리 시간**: 평균 20~30초 (음성 평가), 즉시 (선택형 평가)
- **특징**:
  - 평가 유형별 맞춤 채점 로직
  - EFL 환경 최적화 (한국 발음 특성 반영)
  - 맥락 이해를 통한 지능형 채점
- **채점 방식**:
  - **1교시, 4교시 (음성 평가)**: GPT-4o-transcribe로 전사 후 GPT-4o로 채점
  - **2교시, 3교시, 5교시, 6교시 (선택형 평가)**: 즉시 채점 (정답과 선택 답안 비교)
- **전사 결과 저장**:
  - `transcription_results` JSONB 필드에 저장
  - 구조: `{ openai: { text, confidence, timeline } }`
  - 타임라인 정보를 활용한 망설임 감지 및 오류 분석

#### 2.3.3 교사 관리 시스템

##### 교사 대시보드

- **통계 요약**:
  - 총 학생 수
  - 반 개수
  - 완료된 테스트 수
  - 평균 정확도
- **반별 학생 목록**: 반별로 그룹화된 학생 카드 표시
- **학생 정보**: 이름, 반, 번호, 완료율, 평균 정확도

##### 학생 상세 결과 페이지

- **학생 기본 정보**: 이름, 반, 번호, 학년
- **테스트별 통계**: 6가지 평가 유형별 시도 횟수, 평균 정확도
- **시각화 차트**:
  - 막대 차트: 테스트별 정확도 비교
  - 레이더 차트: 종합 역량 시각화
- **AI 평가 코멘트**: GPT-4o가 생성한 종합 평가 및 개선 제안
- **세션별 상세 기록**: 날짜별로 그룹화된 평가 이력

#### 2.3.4 성취기준 도달 판정 시스템

본 플랫폼은 국가기초학력지원센터의 최소 성취기준을 바탕으로 학생의 성취 수준을 판정하는 시스템을 제공합니다.

##### 혼합 판정 방식

성취기준 도달 여부는 절대 기준과 통계적 기준을 모두 고려하여 판정합니다.

- **절대 기준**: 각 영역별 70% 이상 달성
  - p1_alphabet (알파벳 이름 말하기): 70%
  - p2_segmental_phoneme (음소 분리): 70%
  - p3_suprasegmental_phoneme (강세 및 리듬 패턴): 70%
  - p4_phonics (파닉스 읽기): 70%
  - p5_vocabulary (의미 이해): 70%
  - p6_comprehension (주요 정보 파악): 70%

- **통계적 기준**: Z-score >= -1.0 (하위 16% 미만 제외)
  - 반 평균 및 표준편차를 기반으로 계산
  - 반 학생이 1명이거나 표준편차가 0인 경우 절대 기준만으로 판정
  - Z-score = (학생 정확도 - 반 평균) / 반 표준편차

- **종합 판정**: 절대 기준과 통계적 기준을 모두 만족해야 성취기준 도달로 판정
  - 절대 기준 미달: 성취기준 미도달
  - 절대 기준 달성 + 통계적 기준 미달: 성취기준 미도달
  - 절대 기준 달성 + 통계적 기준 달성: 성취기준 도달

##### 구현 위치

- 구현 파일: src/lib/achievement-standards.ts
- API 엔드포인트: /api/teacher/achievement-standards
- 주요 함수:
  - evaluateAchievement: 단일 영역 성취기준 판정
  - evaluateOverallAchievement: 모든 영역 종합 판정
  - calculateClassStatistics: 반 통계 계산

#### 2.3.5 전사 정확도 검토 시스템

AI 음성 인식 및 채점 시스템의 정확도를 검증하고 개선하기 위한 교사 검토 시스템입니다.

##### 목적

- AI 음성 인식(전사) 정확도 검증
- AI 채점 정확도 검증
- 시스템 개선을 위한 데이터 수집

##### 14가지 리뷰 유형

교사는 각 테스트 결과를 검토하여 다음 14가지 유형 중 하나를 선택합니다:

- 유형 1: 정답 발화 → 정확한 전사 → 정답
- 유형 2: 정답 발화 → 정확한 전사 → 오답
- 유형 3: 정답 발화 → 부정확한 전사 → 정답
- 유형 4: 정답 발화 → 부정확한 전사 → 오답
- 유형 5: 오답 발화 → 정확한 전사 → 정답
- 유형 6: 오답 발화 → 정확한 전사 → 오답
- 유형 7: 오답 발화 → 부정확한 전사 → 정답
- 유형 8: 오답 발화 → 부정확한 전사 → 오답
- 유형 9: 발화 없음 → 부정확한 전사 → 정답
- 유형 10: 발화 없음 → 부정확한 전사 → 오답
- 유형 11: 발화 수정 → 정확한 전사 → 정답
- 유형 12: 발화 수정 → 정확한 전사 → 오답
- 유형 13: 발화 수정 → 부정확한 전사 → 정답
- 유형 14: 발화 수정 → 부정확한 전사 → 오답

##### 통계 지표

- **음성 인식 정확도**: 정확한 전사를 한 경우의 비율
  - 계산 기준: 유형 1, 2, 5, 6, 11, 12
  - 공식: (정확한 전사 수 / 전체 리뷰 수) × 100

- **채점 정확도**: 최종 채점이 올바른 경우의 비율
  - 계산 기준: 유형 1, 3, 5, 7, 9, 11, 13
  - 공식: (올바른 채점 수 / 전체 리뷰 수) × 100

##### 구현 위치

- UI 페이지: src/app/teacher/transcription-accuracy/page.tsx
- API 엔드포인트:
  - /api/teacher/transcription-accuracy/statistics: 통계 조회
  - /api/teacher/transcription-accuracy/review: 리뷰 저장
- 데이터베이스 테이블: transcription_accuracy_reviews

#### 2.3.6 데이터베이스 구조

##### 주요 테이블

**1. test_results 테이블**
- 테스트 결과 저장
- 주요 컬럼:
  - `id`: 기본 키 (bigint, 자동 증가)
  - `user_id`: 사용자 ID (UUID, FK → auth.users.id)
  - `test_type`: 테스트 유형 (text, 예: 'p1_alphabet', 'p2_segmental_phoneme' 등)
  - `question`: 문제 내용 (text)
  - `student_answer`: 학생 답안 (text)
  - `correct_answer`: 정답 (text)
  - `is_correct`: 정답 여부 (boolean)
  - `accuracy`: 정확도 (double precision, 0-100)
  - `error_type`: 오류 유형 (text, 예: 'Letter sounds', 'Hesitation', 'Skipped' 등)
  - `time_taken`: 소요 시간 (integer, 초 단위)
  - `audio_url`: 음성 파일 URL (text, Supabase Storage 경로)
  - `transcription_results`: 전사 결과 (JSONB)
    - 구조: `{ openai: { text: string, confidence: string, timeline: Array<{start: number, end: number, text: string}> } }`
  - `created_at`: 생성 시간 (timestamptz)

**2. user_profiles 테이블**
- 사용자 프로필 및 역할 관리
- 주요 컬럼:
  - `id`: 사용자 ID (UUID, PK, FK → auth.users.id)
  - `full_name`: 전체 이름 (text)
  - `role`: 역할 (text, 'student' 또는 'teacher')
  - `class_name`: 반 이름 (text)
  - `student_number`: 학생 번호 (text)
  - `grade_level`: 학년 (text, 예: '초등 3학년', '초등 4학년')
  - `created_at`, `updated_at`: 생성/수정 시간

**3. teacher_student_assignments 테이블**
- 교사-학생 관계 매핑
- 주요 컬럼:
  - `id`: 기본 키 (UUID)
  - `teacher_id`: 교사 ID (UUID, FK → auth.users.id)
  - `student_id`: 학생 ID (UUID, FK → auth.users.id)
  - `class_name`: 반 이름 (text)
  - `assigned_at`: 배정 시간 (timestamptz)
  - UNIQUE 제약조건: (teacher_id, student_id)

**4. generated_test_items 테이블**
- AI 생성 문항 저장 및 승인 워크플로우
- 주요 컬럼:
  - `id`: 기본 키 (UUID)
  - `test_type`: 테스트 유형 (text)
  - `grade_level`: 학년 수준 (text)
  - `items`: 문항 데이터 (JSONB)
  - `pdf_references`: 참조한 PDF 청크 ID 목록 (JSONB)
  - `curriculum_alignment`: 교육과정 연계 정보 (JSONB)
  - `quality_score`: 품질 점수 (numeric, 0-100)
  - `status`: 상태 (text, 'pending', 'reviewed', 'approved', 'rejected')
  - `generated_by`: 생성자 ID (UUID, FK → auth.users.id)
  - `reviewed_by`: 검토자 ID (UUID, FK → auth.users.id)
  - `review_notes`: 검토 의견 (text)
  - `approved_at`: 승인 시간 (timestamptz)
  - `created_at`, `updated_at`: 생성/수정 시간

**5. curriculum_pdfs 테이블**
- 교육과정 PDF 파일 관리
- 주요 컬럼:
  - `id`: 기본 키 (UUID)
  - `file_name`: 파일명 (text)
  - `file_url`: 파일 URL (text)
  - `uploaded_by`: 업로드자 ID (UUID, FK → auth.users.id)
  - `created_at`: 생성 시간 (timestamptz)

**6. curriculum_pdf_chunks 테이블**
- PDF 청크 저장 (벡터 검색용)
- 주요 컬럼:
  - `id`: 기본 키 (UUID)
  - `pdf_id`: PDF ID (UUID, FK → curriculum_pdfs.id)
  - `page_number`: 페이지 번호 (integer)
  - `content`: 텍스트 내용 (text)
  - `metadata`: 추가 메타데이터 (JSONB)
  - `created_at`: 생성 시간 (timestamptz)

**7. item_approval_workflow 테이블**
- 문항 승인 워크플로우 이력
- 주요 컬럼:
  - `id`: 기본 키 (UUID)
  - `item_id`: 문항 ID (UUID, FK → generated_test_items.id)
  - `action`: 작업 유형 (text, 'review', 'approve', 'reject', 'request_revision')
  - `performed_by`: 수행자 ID (UUID, FK → auth.users.id)
  - `notes`: 의견/메모 (text)
  - `quality_score`: 품질 점수 (numeric)
  - `created_at`: 생성 시간 (timestamptz)

##### 보안 기능

- **Row Level Security (RLS)**: 모든 테이블에 RLS 활성화
  - **학생 권한**:
    - 자신의 `test_results`만 조회 및 삽입 가능
    - 자신의 `user_profiles`만 조회 및 수정 가능
  - **교사 권한**:
    - 담당 학생의 `test_results` 조회 가능
    - 담당 학생의 `user_profiles` 조회 가능
    - 자신의 `teacher_student_assignments` 조회 및 삽입 가능
- **역할 기반 접근 제어**: 역할(role)에 따른 접근 권한 관리
- **인덱스 최적화**:
  - `test_results`: user_id, created_at, test_type, transcription_results (GIN 인덱스)
  - `user_profiles`: role
  - `teacher_student_assignments`: teacher_id, student_id
  - `generated_test_items`: status, grade_level, test_type, created_at

#### 2.3.7 Supabase Storage 구조 및 기능

본 플랫폼은 Supabase Storage를 활용하여 학생들의 음성 평가 파일을 저장하고 관리합니다.

##### Storage 버킷 구성

**버킷 이름**: `student-recordings`
- **용도**: 학생 음성 평가 파일 저장
- **파일 형식**: WebM (audio/webm;codecs=opus)
- **접근 권한**: Public (읽기), Authenticated (업로드)
- **파일 크기 제한**: 50MB
- **허용 MIME 타입**: `audio/webm`

##### 파일 경로 구조

현재 플랫폼은 다음과 같은 계층적 경로 구조를 사용합니다:

```
student-recordings/
├── {studentName}_{userId_8자리}/
│   ├── {YYYY-MM-DD}/          # 평가 세션 날짜
│   │   ├── p1_alphabet/       # 1교시: 알파벳
│   │   │   └── {timestamp}.webm
│   │   ├── p4_phonics/        # 4교시: 파닉스
│   │   │   ├── nwf/           # 무의미 단어
│   │   │   │   └── {timestamp}.webm
│   │   │   ├── wrf/           # 실제 단어
│   │   │   │   └── {timestamp}.webm
│   │   │   └── orf/           # 문장
│   │   │       └── {timestamp}.webm
│   │   └── ...
│   └── {YYYY-MM-DD}/          # 다른 날짜의 평가
│       └── ...
└── ...
```

**경로 생성 규칙**:
- `studentName`: `user_profiles` 테이블의 `full_name` 필드 사용
  - 한글 이름의 경우 로마자로 변환 (예: "김민수" → "GimMinsu")
  - 이름이 없으면 이메일의 @ 앞부분 사용
  - 둘 다 없으면 `student_{userId_8자리}` 형식 사용
- `sessionDate`: 평가 날짜 (YYYY-MM-DD 형식)
- `testType`: 테스트 유형 (p1_alphabet, p4_phonics 등)
- `timestamp`: 파일 생성 시점의 타임스탬프 (밀리초)

**예시 경로**:
- `GimMinsu_a1b2c3d4/2025-01-15/p1_alphabet/1705123456789.webm`
- `student_a1b2c3d4/2025-01-15/p4_phonics/nwf/1705123457890.webm`

##### 경로 생성 함수

**구현 위치**: `src/lib/storage-path.ts`

주요 함수:
- `generateStoragePath(userId, testType, timestamp?)`: 새로운 스토리지 경로 생성
- `getStudentName(userId)`: 학생 이름 조회 (user_profiles → auth.users 순서로 시도)
- `getSessionDate()`: 현재 세션 날짜 반환 (YYYY-MM-DD)
- `parseStoragePath(path)`: 기존 경로 파싱 (마이그레이션용)

##### 파일 업로드 프로세스

1. **음성 파일 생성**: 브라우저에서 MediaRecorder API로 WebM 형식 파일 생성
2. **경로 생성**: `generateStoragePath()` 함수로 저장 경로 생성
3. **업로드**: Supabase Storage API를 통해 파일 업로드
   ```typescript
   await supabase.storage
     .from('student-recordings')
     .upload(storagePath, arrayBuffer, {
       contentType: 'audio/webm',
       upsert: false
     })
   ```
4. **URL 저장**: 업로드된 파일의 경로를 `test_results` 테이블의 `audio_url` 필드에 저장

##### 파일 접근 방식

플랫폼은 두 가지 방식으로 음성 파일에 접근합니다:

1. **Signed URL 방식** (우선 시도):
   ```typescript
   const { data } = await supabase.storage
     .from('student-recordings')
     .createSignedUrl(audioPath, 3600); // 1시간 유효
   ```
   - 임시 서명된 URL 생성 (1시간 유효)
   - 보안이 필요한 경우 사용

2. **Public URL 방식** (폴백):
   ```typescript
   const publicUrl = `${supabaseUrl}/storage/v1/object/public/student-recordings/${audioPath}`;
   ```
   - Public 버킷이므로 직접 접근 가능
   - Signed URL이 실패할 경우 사용

**구현 위치**:
- `src/components/TeacherAudioPlayer.tsx`: 교사용 오디오 플레이어
- `src/components/AudioResultTable.tsx`: 학생 결과 테이블의 오디오 플레이어

##### RLS (Row Level Security) 정책

Storage 버킷에 대한 접근 제어는 다음과 같이 설정됩니다:

```sql
-- 1. 모든 사용자가 읽기 가능 (Public)
CREATE POLICY "Allow public read access" ON storage.objects
FOR SELECT USING (bucket_id = 'student-recordings');

-- 2. 인증된 사용자가 업로드 가능
CREATE POLICY "Allow authenticated users to upload" ON storage.objects
FOR INSERT WITH CHECK (
  bucket_id = 'student-recordings' 
  AND auth.role() = 'authenticated'
);

-- 3. 인증된 사용자가 업데이트 가능
CREATE POLICY "Allow authenticated users to update" ON storage.objects
FOR UPDATE USING (
  bucket_id = 'student-recordings' 
  AND auth.role() = 'authenticated'
);
```

**정책 요약**:
- **읽기**: 모든 사용자 (Public 버킷)
- **업로드**: 인증된 사용자만
- **업데이트**: 인증된 사용자만
- **삭제**: 기본적으로 비활성화 (필요시 별도 정책 추가)

##### Storage 마이그레이션

프로젝트 초기에는 다른 경로 구조를 사용했으나, 현재는 학생 이름 기반 구조로 변경되었습니다. 기존 파일을 새 구조로 마이그레이션하는 스크립트가 제공됩니다:

**마이그레이션 스크립트**: `scripts/migrate-storage.ts`

**기존 구조**:
```
student-recordings/
├── p1_alphabet/{userId}/{timestamp}.webm
└── p4_phonics/{userId}/{timestamp}.webm
```

**새 구조**:
```
student-recordings/
├── {studentName}_{userId_8자리}/{YYYY-MM-DD}/{testType}/{timestamp}.webm
```

**마이그레이션 실행**:
```bash
# Dry-run (미리보기)
npm run migrate-storage

# 실제 실행
npm run migrate-storage -- --execute
```

##### Storage 최적화

1. **경로 기반 검색**: 학생 이름과 날짜로 빠른 파일 검색
2. **자동 정리**: 오래된 파일은 수동 또는 스케줄러로 정리 가능
3. **CDN 활용**: Supabase Storage는 글로벌 CDN을 통해 빠른 파일 전송 제공
4. **비용 관리**: Public 버킷은 대역폭 비용이 발생하므로 모니터링 필요

##### 파일 접근 오류 처리

음성 파일 접근 시 다음과 같은 폴백 메커니즘을 사용합니다:

1. **Signed URL 시도**: 우선적으로 임시 서명된 URL 생성 시도
2. **Public URL 시도**: Signed URL 실패 시 Public URL 사용
3. **경로 변환 시도**: 기존 경로 형식과 새 경로 형식 모두 시도
4. **에러 표시**: 모든 시도 실패 시 사용자에게 에러 메시지 표시

**구현 예시** (`src/components/AudioResultTable.tsx`):
- 여러 경로 형식을 순차적으로 시도
- 각 경로에 대해 Signed URL과 Public URL 모두 시도
- 성공한 첫 번째 URL 사용

#### 2.3.8 AI 문항 생성 및 관리 시스템

본 플랫폼은 GPT-4o를 활용하여 교육과정 PDF를 기반으로 평가 문항을 자동 생성하고, 품질 검증 및 승인 워크플로우를 통해 관리하는 시스템을 제공합니다.

##### 문항 생성 프로세스

1. **교육과정 PDF 업로드**
   - 교사가 교육과정 PDF 파일을 업로드
   - PDF는 페이지별로 청크(chunk)로 분할되어 `curriculum_pdf_chunks` 테이블에 저장
   - 각 청크는 벡터 임베딩으로 변환되어 의미 기반 검색 가능

2. **문항 생성 요청**
   - 교사가 문항 생성 페이지에서 다음 정보 입력:
     - 테스트 유형 (p1_alphabet ~ p6_comprehension)
     - 학년 수준 (초등 1학년 ~ 초등 4학년)
     - 생성할 문항 수
   - GPT-4o가 교육과정 PDF 청크를 참조하여 문항 생성

3. **품질 검증**
   - 생성된 문항은 자동으로 품질 검증 수행:
     - DIBELS 준수도
     - 학년 수준 적절성
     - 교육과정 연계도
     - 난이도 적절성
     - 문법 정확도
   - 각 항목별 점수 및 전체 품질 점수(0-100) 계산

4. **승인 워크플로우**
   - **pending**: 생성 완료, 검토 대기
   - **reviewed**: 교사가 검토 완료
   - **approved**: 승인 완료, 학생 평가에 사용 가능
   - **rejected**: 거부됨, 사용 불가
   - 각 단계별 이력은 `item_approval_workflow` 테이블에 기록

5. **문항 사용**
   - 승인된 문항만 학생 평가에 사용
   - 학생이 평가를 시작하면 최신 승인 문항을 자동으로 로드
   - 승인된 문항이 없으면 기본 문항(fallback) 사용

##### 구현 위치

- **문항 생성 Agent**: `src/lib/agents/ItemGeneratorAgent.ts`
- **품질 검증 Agent**: `src/lib/agents/QualityValidatorAgent.ts`
- **승인 워크플로우 Agent**: `src/lib/agents/ApprovalWorkflowAgent.ts`
- **오케스트레이터**: `src/lib/agents/OrchestratorAgent.ts`
- **API 엔드포인트**: 
  - `/api/agents/generate-items`: 문항 생성
  - `/api/generated-items`: 생성된 문항 조회
  - `/api/generated-items/[id]/approve`: 문항 승인
  - `/api/generated-items/[id]/reject`: 문항 거부
  - `/api/test-items`: 승인된 문항 조회 (학생 평가용)

---

## 3. 진단 플랫폼 작동 방법/예시 등

### 3.1 플랫폼 작동 방법

#### 3.1.1 학생 평가 프로세스

학생이 평가를 진행하는 전체 프로세스는 다음과 같습니다:

```mermaid
flowchart TD
    A[로그인] --> B[로비 화면 접속]
    B --> C{평가 유형 선택}
    C -->|1교시| D1[알파벳 평가]
    C -->|2교시| D2[음소 분리 평가]
    C -->|3교시| D3[강세/리듬 평가]
    C -->|4교시| D4[파닉스 평가]
    C -->|5교시| D5[어휘 평가]
    C -->|6교시| D6[이해력 평가]
    
    D1 --> E[평가 설명 화면]
    D2 --> E
    D3 --> E
    D4 --> E
    D5 --> E
    D6 --> E
    
    E --> F[시작하기 버튼 클릭]
    F --> G{평가 유형별<br/>진행}
    
    G -->|음성 녹음| H1[음성 녹음 진행<br/>1분 제한]
    G -->|듣기+선택| H2[문제 듣고 선택<br/>1분 제한]
    G -->|읽기+선택| H3[문제 읽고 선택<br/>1분 제한]
    
    H1 --> I[제출 버튼 클릭]
    H2 --> I
    H3 --> I
    
    I --> J[AI 채점 진행<br/>로딩 화면]
    J --> K[결과 화면]
    K --> L[정확도 표시]
    K --> M[상세 피드백]
    K --> N[AI 코멘트]
    
    L --> O[다음 평가 또는<br/>결과 확인]
    M --> O
    N --> O
    
    style A fill:#e1f5ff
    style J fill:#f3e5f5
    style K fill:#e8f5e9
```

**그림 5. 학생 평가 프로세스 플로우차트**

학생은 로그인 후 원하는 평가 유형을 선택하고, 평가 설명을 확인한 뒤 평가를 시작합니다. 평가 유형에 따라 음성 녹음, 듣기+선택, 읽기+선택 방식으로 진행되며, 제출 후 AI가 자동으로 채점하여 결과를 제공합니다.

#### 3.1.2 음성 녹음 및 처리 과정

음성 평가(1교시, 4교시)에서 음성을 녹음하고 처리하는 상세 과정은 다음과 같습니다:

```mermaid
sequenceDiagram
    participant S as 학생
    participant B as 브라우저
    participant MR as MediaRecorder
    participant API as API 서버
    participant ST as Supabase Storage
    participant OAI as OpenAI API
    participant DB as 데이터베이스
    
    S->>B: 평가 시작 버튼 클릭
    B->>B: 마이크 권한 요청
    S->>B: 마이크 권한 허용
    B->>MR: MediaRecorder 초기화<br/>(audio/webm;codecs=opus)
    
    loop 각 문항마다
        B->>MR: 녹음 시작
        S->>MR: 음성 입력 (최대 5초)
        MR->>MR: 오디오 청크 수집
        MR->>B: 녹음 중지 (5초 타임아웃 또는 수동)
        B->>B: Blob 생성 (WebM 형식)
        B->>API: 음성 파일 제출 (FormData)
    end
    
    API->>API: 인증 확인
    API->>ST: 음성 파일 업로드<br/>(student-recordings 버킷)
    ST-->>API: 업로드 완료 (URL)
    
    API->>OAI: GPT-4o-transcribe 호출<br/>(음성 파일 + 프롬프트)
    OAI-->>API: 전사 결과<br/>(text, confidence, timeline)
    
    API->>OAI: GPT-4o 채점 요청<br/>(전사 결과 + 평가 기준)
    OAI-->>API: 채점 결과<br/>(정답/오답, 오류 유형, 정확도)
    
    API->>DB: 결과 저장<br/>(전사 결과 포함)
    DB-->>API: 저장 완료
    API-->>B: 평가 결과 반환
    B-->>S: 결과 표시
```

**그림 6. 음성 녹음 및 처리 프로세스 시퀀스 다이어그램**

**주요 기술 세부사항**:

1. **마이크 권한 요청**: 
   - `navigator.mediaDevices.getUserMedia({ audio: true })` 호출
   - 사용자가 권한을 허용해야 녹음 가능

2. **MediaRecorder 초기화**:
   - `new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' })`
   - WebM 형식으로 고품질 오디오 압축

3. **실시간 오디오 캡처**:
   - `mediaRecorder.ondataavailable` 이벤트로 오디오 청크 수집
   - `audioChunksRef.current.push(event.data)`로 메모리에 저장

4. **Blob 생성 및 제출**:
   - `new Blob(audioChunks, { type: 'audio/webm' })`로 최종 파일 생성
   - FormData를 통해 API 서버로 전송

5. **Supabase Storage 업로드**:
   - 경로 형식: `p1_alphabet/{userId}/{timestamp}.webm` 또는 `p4_phonics/{userId}/{testType}/{timestamp}.webm`
   - 업로드된 파일 URL을 `audio_url` 필드에 저장

6. **음성 전사**:
   - OpenAI GPT-4o-transcribe API 호출
   - 프롬프트 매개변수로 평가 유형별 맥락 제공
   - 반환값: `{ text, confidence, timeline }`
   - timeline은 `[{start, end, text}]` 형식의 세그먼트 배열

7. **채점 처리**:
   - 1교시: 복잡한 채점 로직 (문자 이름 vs 문자 소리 구분, 한국어 발음 인정, 망설임 감지 등)
   - 4교시: 간단한 채점 로직 (전사 결과가 정답을 포함하는지 확인)

8. **결과 저장**:
   - `transcription_results` JSONB 필드에 전사 결과 저장
   - 구조: `{ openai: { text, confidence, timeline } }`

#### 3.1.3 AI 채점 프로세스

AI가 평가를 채점하는 상세 프로세스는 다음과 같습니다:

```mermaid
sequenceDiagram
    participant S as 학생
    participant API as API 서버
    participant ST as Storage
    participant W as Whisper API
    participant G as GPT-4o API
    participant DB as 데이터베이스
    
    S->>API: 평가 제출 (음성 파일 URL)
    
    API->>ST: 음성 파일 다운로드
    ST-->>API: 음성 파일 (Blob)
    
    API->>W: 음성 전사 요청
    W-->>API: 전사 결과 (텍스트)
    
    Note over API,G: 평가 유형별 채점 로직 적용
    
    API->>G: 채점 요청<br/>(전사 결과 + 평가 기준)
    
    G->>G: 문항별 정답/오답 판정
    G->>G: 정확도 계산
    G->>G: 피드백 생성
    G->>G: 종합 코멘트 작성
    
    G-->>API: 채점 결과 + 피드백
    
    API->>DB: 결과 저장
    DB-->>API: 저장 완료
    
    API-->>S: 평가 결과 반환
```

**그림 7. AI 채점 프로세스 시퀀스 다이어그램**

학생이 평가를 제출하면 평가 유형에 따라 다음과 같이 처리됩니다:

**음성 평가 (1교시, 4교시)**:
1. 음성 파일이 Supabase Storage에 업로드
2. OpenAI GPT-4o-transcribe API로 전송되어 텍스트로 전사 (타임라인 정보 포함)
3. 전사 결과와 타임라인을 GPT-4o API로 전송
4. 평가 유형별 채점 로직에 따라 정답/오답 판정, 정확도 계산, 오류 유형 분류 수행
5. 최종 결과(전사 결과 포함)는 데이터베이스에 저장되고 학생에게 반환

**선택형 평가 (2교시, 3교시, 5교시, 6교시)**:
1. 선택한 답안과 정답을 즉시 비교
2. 정답/오답 판정 및 정확도 계산 (정답: 100%, 오답: 0%)
3. 결과는 데이터베이스에 저장되고 학생에게 즉시 반환

#### 3.1.4 문항 생성 및 관리 프로세스

교사가 AI를 활용하여 평가 문항을 생성하고 관리하는 프로세스는 다음과 같습니다:

```mermaid
flowchart TD
    A[교사 로그인] --> B[문항 생성 페이지 접근]
    B --> C[문항 생성 요청]
    C --> C1[테스트 유형 선택]
    C --> C2[학년 수준 선택]
    C --> C3[생성할 문항 수 입력]
    
    C1 --> D[GPT-4o 문항 생성]
    C2 --> D
    C3 --> D
    
    D --> E[교육과정 PDF 참조]
    E --> F[문항 생성 완료]
    
    F --> G[자동 품질 검증]
    G --> G1[DIBELS 준수도 검증]
    G --> G2[학년 수준 적절성 검증]
    G --> G3[교육과정 연계도 검증]
    G --> G4[난이도 적절성 검증]
    G --> G5[문법 정확도 검증]
    
    G1 --> H[품질 점수 계산]
    G2 --> H
    G3 --> H
    G4 --> H
    G5 --> H
    
    H --> I[데이터베이스 저장<br/>status: pending]
    
    I --> J{교사 검토}
    J -->|승인| K[status: approved]
    J -->|거부| L[status: rejected]
    J -->|수정 요청| M[status: reviewed]
    
    K --> N[학생 평가에 사용 가능]
    L --> O[사용 불가]
    M --> P[재검토 대기]
    
    style A fill:#fff4e1
    style D fill:#f3e5f5
    style G fill:#e8f5e9
    style K fill:#c8e6c9
    style L fill:#ffcdd2
```

**그림 8. 문항 생성 및 관리 프로세스 플로우차트**

**주요 단계**:

1. **문항 생성 요청**
   - 교사가 문항 생성 페이지(`/teacher/generate-items`)에서 요청
   - 테스트 유형, 학년 수준, 생성할 문항 수 입력
   - GPT-4o가 교육과정 PDF 청크를 참조하여 문항 생성

2. **품질 검증**
   - 생성된 문항은 자동으로 5가지 항목 검증:
     - DIBELS 준수도: DIBELS 평가 기준 준수 여부
     - 학년 수준 적절성: 해당 학년 수준에 적합한지
     - 교육과정 연계도: 교육과정과의 연계성
     - 난이도 적절성: 적절한 난이도인지
     - 문법 정확도: 문법적으로 정확한지
   - 각 항목별 점수 및 전체 품질 점수(0-100) 계산

3. **승인 워크플로우**
   - 생성된 문항은 `pending` 상태로 저장
   - 교사가 문항 검토 페이지(`/teacher/test-items`)에서 검토
   - 승인 시 `approved` 상태로 변경, 학생 평가에 사용 가능
   - 거부 시 `rejected` 상태로 변경, 사용 불가
   - 각 단계별 이력은 `item_approval_workflow` 테이블에 기록

4. **문항 사용**
   - 학생이 평가를 시작하면 `/api/test-items` API 호출
   - 최신 승인된 문항(`status='approved'`)을 조회
   - 승인된 문항이 없으면 기본 문항(fallback) 사용

#### 3.1.5 성취기준 판정 프로세스

학생의 성취기준 도달 여부를 판정하는 프로세스는 다음과 같습니다:

1. **학생 정확도 수집**: 학생의 각 평가 유형별 최신 정확도를 수집합니다.

2. **반 통계 계산**: 동일 반 학생들의 평가 결과를 기반으로 다음을 계산합니다:
   - 반 평균 정확도
   - 반 표준편차
   - 학생 수

3. **절대 기준 판정**: 각 영역별로 학생의 정확도가 70% 이상인지 확인합니다.

4. **통계적 기준 판정**: 반 통계가 있는 경우 Z-score를 계산하여 -1.0 이상인지 확인합니다.
   - Z-score = (학생 정확도 - 반 평균) / 반 표준편차
   - 반 학생이 1명이거나 표준편차가 0인 경우 통계적 기준은 적용하지 않습니다.

5. **종합 판정**: 절대 기준과 통계적 기준을 모두 만족하는 영역을 성취기준 도달로 판정합니다.

6. **결과 생성**: 6가지 영역별 도달 여부와 전체 도달 영역 수를 계산하여 결과를 생성합니다.

```mermaid
flowchart TD
    A[학생 평가 결과 수집] --> B[학생 정확도 추출]
    B --> C[반 통계 계산]
    C --> C1[반 평균 계산]
    C --> C2[반 표준편차 계산]
    C --> C3[학생 수 확인]
    
    B --> D[절대 기준 판정]
    D --> D1{정확도 >= 70%?}
    D1 -->|예| D2[절대 기준 달성]
    D1 -->|아니오| D3[절대 기준 미달]
    
    C1 --> E[통계적 기준 판정]
    C2 --> E
    C3 --> E
    E --> E1{반 학생 수 > 1<br/>AND<br/>표준편차 > 0?}
    E1 -->|예| E2[Z-score 계산]
    E1 -->|아니오| E3[통계적 기준 미적용]
    
    E2 --> E4{Z-score >= -1.0?}
    E4 -->|예| E5[통계적 기준 달성]
    E4 -->|아니오| E6[통계적 기준 미달]
    
    D2 --> F[종합 판정]
    D3 --> F
    E5 --> F
    E6 --> F
    E3 --> F
    
    F --> F1{절대 기준 달성<br/>AND<br/>통계적 기준 달성?}
    F1 -->|예| G[성취기준 도달]
    F1 -->|아니오| H[성취기준 미도달]
    
    G --> I[결과 생성]
    H --> I
    I --> I1[6개 영역별 도달 여부]
    I --> I2[도달한 영역 수 계산]
    I --> I3[전체 도달 여부 판정]
    
    style D2 fill:#c8e6c9
    style D3 fill:#ffcdd2
    style E5 fill:#c8e6c9
    style E6 fill:#ffcdd2
    style G fill:#c8e6c9
    style H fill:#ffcdd2
```

**그림 9. 성취기준 판정 프로세스 플로우차트**

#### 3.1.4 전사 정확도 검토 프로세스

교사가 AI 음성 인식 및 채점 시스템의 정확도를 검토하는 프로세스는 다음과 같습니다:

1. **테스트 결과 조회**: 교사 대시보드에서 전사 정확도 검토 페이지에 접근합니다.

2. **오디오 재생 및 전사 확인**: 각 테스트 결과에 대해 다음을 확인합니다:
   - 학생의 실제 발화를 오디오로 재생하여 확인
   - AI가 전사한 텍스트 결과 확인
   - 최종 채점 결과 확인

3. **리뷰 유형 선택**: 14가지 리뷰 유형 중 해당하는 유형을 선택합니다.
   - 발화 정확도 (정답/오답/없음/수정)
   - 전사 정확도 (정확/부정확)
   - 채점 정확도 (정답/오답)

4. **메모 작성**: 필요시 추가 메모를 작성합니다.

5. **리뷰 저장**: 선택한 리뷰 유형과 메모를 데이터베이스에 저장합니다.

6. **통계 자동 계산**: 저장된 리뷰를 기반으로 다음 통계가 자동으로 계산됩니다:
   - 음성 인식 정확도
   - 채점 정확도
   - 리뷰 유형별 분포

7. **시스템 개선**: 수집된 데이터를 분석하여 AI 시스템 개선에 활용합니다.

```mermaid
flowchart TD
    A[교사 로그인] --> B[전사 정확도 검토 페이지 접근]
    B --> C[테스트 유형 선택<br/>1교시 또는 4교시]
    C --> D[날짜 범위 설정]
    D --> E[테스트 결과 목록 조회]
    
    E --> F[각 테스트 결과 검토]
    F --> F1[오디오 재생]
    F --> F2[전사 결과 확인]
    F --> F3[채점 결과 확인]
    
    F1 --> G[리뷰 유형 선택]
    F2 --> G
    F3 --> G
    
    G --> G1{14가지 리뷰 유형 중<br/>선택}
    G1 --> G2[발화 정확도<br/>정답/오답/없음/수정]
    G1 --> G3[전사 정확도<br/>정확/부정확]
    G1 --> G4[채점 정확도<br/>정답/오답]
    
    G2 --> H[메모 작성<br/>선택사항]
    G3 --> H
    G4 --> H
    
    H --> I[리뷰 저장]
    I --> J[데이터베이스 저장]
    
    J --> K[통계 자동 계산]
    K --> K1[음성 인식 정확도]
    K --> K2[채점 정확도]
    K --> K3[리뷰 유형별 분포]
    
    K1 --> L[시스템 개선]
    K2 --> L
    K3 --> L
    
    style A fill:#fff4e1
    style G fill:#e1f5ff
    style I fill:#c8e6c9
    style L fill:#e8f5e9
```

**그림 10. 전사 정확도 검토 워크플로우**

#### 3.1.5 교사 대시보드 활용

교사가 대시보드를 활용하는 프로세스는 다음과 같습니다:

```mermaid
flowchart TD
    A[교사 로그인] --> B[로비 화면]
    B --> C[교사 관리 대시보드<br/>버튼 클릭]
    C --> D[대시보드 메인]
    
    D --> E[통계 요약 확인]
    E --> E1[총 학생 수]
    E --> E2[반 개수]
    E --> E3[완료된 테스트 수]
    E --> E4[평균 정확도]
    
    D --> F[반별 학생 목록]
    F --> G{학생 선택}
    
    G --> H[학생 상세 페이지]
    
    H --> I[테스트별 통계]
    H --> J[시각화 차트]
    H --> K[AI 평가 코멘트]
    H --> L[세션별 상세 기록]
    
    I --> M[막대 차트<br/>정확도 비교]
    J --> N[레이더 차트<br/>종합 역량]
    
    K --> O[개선 제안 확인]
    L --> P[날짜별 평가 이력]
    
    style A fill:#fff4e1
    style D fill:#e8f5e9
    style H fill:#e1f5ff
```

**그림 11. 교사 대시보드 활용 프로세스**

교사는 대시보드에서 전체 통계를 확인하고, 반별로 그룹화된 학생 목록을 확인할 수 있습니다. 특정 학생을 선택하면 해당 학생의 상세 결과 페이지에서 테스트별 통계, 시각화 차트, AI 평가 코멘트, 세션별 상세 기록을 확인할 수 있습니다.

### 3.2 사용자 사용 방법

#### 3.2.1 학생 사용 가이드

##### 1단계: 로그인

1. 웹 브라우저에서 플랫폼 주소로 접속합니다.
2. 교사가 제공한 이메일과 비밀번호로 로그인합니다.
3. 로그인 성공 시 마법학교 테마의 로비 화면으로 이동합니다.

##### 2단계: 평가 선택

로비 화면에서 6가지 평가 유형 중 원하는 평가를 선택합니다:

- **1교시: 고대 룬 문자 해독 시험** - 알파벳 이름 말하기
- **2교시: 소리의 원소 분리 시험** - 음소 분리
- **3교시: 마법 리듬 패턴 시험** - 강세 및 리듬 패턴
- **4교시: 마법 주문 읽기 시험** - 파닉스 읽기
- **5교시: 마법서 그림 해석 시험** - 의미 이해
- **6교시: 고대 전설 이해 시험** - 주요 정보 파악

##### 3단계: 평가 진행

평가 유형에 따라 다음과 같이 진행합니다:

**음성 녹음 평가 (1교시, 4교시)**:
1. 평가 설명 화면을 확인합니다.
2. "시작하기" 버튼을 클릭합니다.
3. 브라우저에서 마이크 권한 요청이 나타나면 "허용"을 선택합니다.
4. 화면에 표시된 내용(알파벳 또는 단어/문장)을 읽으면서 마이크로 음성을 녹음합니다.
5. 각 문항마다 최대 5초 동안 녹음되며, 자동으로 다음 문항으로 이동합니다.
6. 1분 동안 최대한 많은 문제를 해결합니다.
7. "제출" 버튼을 클릭하거나 시간이 종료되면 자동으로 제출됩니다.

**듣기 + 선택 평가 (2교시, 3교시)**:
1. 평가 설명 화면을 확인합니다.
2. "시작하기" 버튼을 클릭합니다.
3. "듣기" 버튼을 클릭하여 문제를 듣습니다.
4. 두 개의 선택지 중 정답을 선택합니다.
5. 1분 동안 최대한 많은 문제를 해결합니다.
6. "제출" 버튼을 클릭합니다.

**읽기 + 선택 평가 (5교시, 6교시)**:
1. 평가 설명 화면을 확인합니다.
2. "시작하기" 버튼을 클릭합니다.
3. 화면에 표시된 문제를 읽거나 "듣기" 버튼으로 듣습니다.
4. 여러 선택지 중 정답을 선택합니다.
5. 1분 동안 최대한 많은 문제를 해결합니다.
6. "제출" 버튼을 클릭합니다.

##### 4단계: 결과 확인

1. AI 채점이 진행되는 동안 잠시 기다립니다 (약 30초).
2. 결과 화면에서 다음 정보를 확인합니다:
   - **정확도**: 백분율로 표시
   - **정답/오답 개수**: 맞춘 문제와 틀린 문제 수
   - **상세 피드백**: 문항별 정답/오답 정보
   - **AI 코멘트**: 종합 평가 및 개선 제안
3. "결과 확인" 버튼을 클릭하면 세션별 평가 이력을 확인할 수 있습니다.

#### 3.2.2 교사 사용 가이드

##### 1단계: 교사 계정 설정

교사 계정은 시스템 관리자가 Supabase에서 직접 설정합니다:

1. Supabase 대시보드에서 교사 계정 생성
2. `user_profiles` 테이블에서 role을 'teacher'로 설정
3. 학생 프로필 생성 및 `teacher_student_assignments` 테이블에 교사-학생 매핑 설정

##### 2단계: 대시보드 접근

1. 교사 계정으로 로그인합니다.
2. 로비 화면에서 "🎓 교사 관리 대시보드" 버튼을 클릭합니다.
3. 대시보드 메인 화면으로 이동합니다.

##### 3단계: 전체 통계 확인

대시보드 메인 화면에서 다음 통계를 확인할 수 있습니다:

- **총 학생 수**: 담당하는 전체 학생 수
- **반 개수**: 관리하는 반의 개수
- **완료된 테스트 수**: 학생들이 완료한 총 테스트 수
- **평균 정확도**: 전체 학생의 평균 정확도

##### 4단계: 학생별 상세 분석

1. 반별 학생 목록에서 분석하고 싶은 학생의 카드를 클릭합니다.
2. 학생 상세 페이지에서 다음 정보를 확인합니다:

   **테스트별 통계 카드**:
   - 각 평가 유형(1교시~6교시)별 시도 횟수
   - 평균 정확도
   - 색상 코딩으로 성적 수준 시각화 (높음: 초록, 중간: 노랑, 낮음: 빨강)

   **시각화 차트**:
   - **막대 차트**: 6가지 평가 유형별 정확도를 막대 그래프로 비교
   - **레이더 차트**: 6가지 평가 영역의 종합 역량을 시각화하여 강점과 약점 파악

   **AI 평가 코멘트**:
   - GPT-4o가 생성한 종합 평가
   - 학생의 강점과 약점 분석
   - 개선 제안 및 학습 방향 안내

   **세션별 상세 기록**:
   - 날짜별로 그룹화된 평가 이력
   - 각 평가를 클릭하면 문항별 상세 결과 확인 가능
   - 시간에 따른 학습 진도 추이 파악

   **성취기준 도달 여부**:
   - 6가지 영역별 성취기준 도달 여부 표시
   - 절대 기준 달성 여부 (70% 이상)
   - 통계적 기준 달성 여부 (Z-score >= -1.0)
   - 종합 판정 결과 (도달/미도달)
   - 도달한 영역 수 및 전체 영역 수

##### 5단계: 전사 정확도 검토

1. 교사 대시보드에서 "전사 정확도 검토" 메뉴를 클릭합니다.
2. 검토할 테스트 유형을 선택합니다 (1교시 또는 4교시).
3. 날짜 범위를 설정하여 검토할 기간을 지정합니다.
4. 각 테스트 결과에 대해 다음을 수행합니다:
   - 오디오 재생 버튼을 클릭하여 학생의 실제 발화를 확인
   - AI가 전사한 텍스트 결과 확인
   - 타임라인 정보 확인 (음성 세그먼트별 시작/종료 시간)
   - 최종 채점 결과 확인
   - 14가지 리뷰 유형 중 해당하는 유형 선택
   - 필요시 메모 작성
   - 저장 버튼 클릭
5. 통계 대시보드에서 다음을 확인합니다:
   - 전체 리뷰 수
   - 리뷰 유형별 분포
   - 음성 인식 정확도 (정확한 전사 비율)
   - 채점 정확도 (올바른 채점 비율)
   - 리뷰 유형별 통계 (1-14번 유형별 개수 및 비율)

##### 6단계: 문항 생성 및 관리

1. 교사 대시보드에서 "문항 생성" 메뉴를 클릭합니다.
2. 문항 생성 요청:
   - 테스트 유형 선택 (1교시 ~ 6교시)
   - 학년 수준 선택 (초등 1학년 ~ 초등 4학년)
   - 생성할 문항 수 입력
   - "문항 생성" 버튼 클릭
3. 생성 완료 후 품질 점수 확인:
   - DIBELS 준수도 점수
   - 학년 수준 적절성 점수
   - 교육과정 연계도 점수
   - 난이도 적절성 점수
   - 문법 정확도 점수
   - 전체 품질 점수 (0-100)
4. 문항 검토 및 승인:
   - "문항 관리" 페이지에서 생성된 문항 목록 확인
   - 각 문항의 상세 내용 및 품질 점수 확인
   - 승인/거부/수정 요청 선택
   - 필요시 검토 의견 작성
5. 승인된 문항은 자동으로 학생 평가에 사용됩니다.

##### 6단계: 데이터 활용

교사는 대시보드의 정보를 활용하여:

- **학생별 맞춤 지도**: 약점 영역을 파악하여 개별 학습 지도
- **반 전체 분석**: 반 평균과 비교하여 학급 수준 파악
- **학부모 상담 자료**: 시각화 차트와 AI 코멘트를 활용한 상담 자료 작성
- **수업 계획 수립**: 학생들의 전반적인 수준을 파악하여 수업 계획 수립
- **성취기준 도달 관리**: 학생별 성취기준 도달 여부를 확인하여 보충 지도 계획 수립
- **시스템 품질 관리**: 전사 정확도 검토를 통해 AI 시스템의 정확도를 모니터링하고 개선

### 3.3 실제 사용 예시

#### 3.3.1 평가 시나리오

**시나리오 1: 초등학교 3학년 학생의 1교시 평가**

김민수 학생(초등 3학년)이 1교시 알파벳 평가를 진행합니다.

1. **로그인 및 평가 선택**
   - 로그인 후 로비 화면에서 "1교시: 고대 룬 문자 해독 시험" 버튼 클릭

2. **평가 진행**
   - 평가 설명: "1분 동안 화면에 나타나는 알파벳을 읽어주세요"
   - 시작하기 버튼 클릭
   - 화면에 알파벳이 순차적으로 표시됨 (예: L/l, E, m, S, O, ...)
   - 학생이 마이크로 알파벳 이름을 읽음: "엘, 이, 엠, 에스, 오, ..."
   - 1분 경과 시 자동 종료

3. **AI 채점 과정**
   - 음성 파일이 OpenAI Whisper로 전사됨
   - 전사 결과: "el, i, em, es, o, ..."
   - GPT-4o가 각 알파벳별로 정답/오답 판정
   - 정확도 계산: 45/52 = 86.5%

4. **결과 확인**
   - 화면에 "정확도: 86.5%" 표시
   - 상세 피드백: "L/l 정답, E 정답, m 정답, ..."
   - AI 코멘트: "알파벳 인식 능력이 우수합니다. 소문자와 대문자 구분에 일부 오류가 있었습니다."

**시나리오 2: 초등학교 4학년 학생의 6교시 평가**

이영희 학생(초등 4학년)이 6교시 이해력 평가를 진행합니다.

1. **평가 진행**
   - "Look at this ball. Wow! It is big. It is red." 대화를 듣음
   - 한국어 질문: "묘사하는 내용에 알맞은 공을 고르시오"
   - 선택지: 작은 빨간색 공, 큰 빨간색 공, 큰 파란색 공, 작은 파란색 공
   - 학생이 "큰 빨간색 공" 이미지 선택

2. **결과**
   - 정답: "큰 빨간색 공"
   - 학생 답안: "큰 빨간색 공" ✓
   - 정확도: 40/40 = 100%

#### 3.3.2 결과 분석 예시

**교사 대시보드에서 학생 분석**

담임교사가 김민수 학생의 평가 결과를 분석합니다.

**대시보드 메인 화면**:
- 총 학생 수: 25명
- 반 개수: 1개
- 완료된 테스트 수: 125개
- 평균 정확도: 78.5%

**김민수 학생 상세 페이지**:

**테스트별 통계**:
- 1교시 (알파벳): 시도 3회, 평균 86.5% (초록)
- 2교시 (음소 분리): 시도 2회, 평균 75.0% (노랑)
- 3교시 (강세/리듬): 시도 2회, 평균 70.0% (노랑)
- 4교시 (파닉스): 시도 3회, 평균 82.0% (초록)
- 5교시 (어휘): 시도 2회, 평균 85.0% (초록)
- 6교시 (이해력): 시도 2회, 평균 88.0% (초록)

**시각화 차트 분석**:
- **막대 차트**: 1교시, 4교시, 5교시, 6교시가 높은 정확도를 보임. 2교시와 3교시는 상대적으로 낮음.
- **레이더 차트**: 전반적으로 균형 잡힌 역량을 보이나, 음소 분리와 강세/리듬 영역에서 약점 발견.

**AI 평가 코멘트**:
> "김민수 학생은 알파벳 인식, 파닉스, 어휘, 이해력 영역에서 우수한 성적을 보이고 있습니다. 특히 이해력 영역에서 높은 정확도를 보여 내용 파악 능력이 뛰어납니다. 다만 음소 분리와 강세/리듬 영역에서 개선이 필요합니다. 최소대립쌍 듣기 연습과 강세 패턴 학습을 통해 발음 능력을 향상시킬 수 있습니다."

**세션별 상세 기록**:
- 2025-01-15: 1교시 (86.5%), 2교시 (75.0%), 3교시 (70.0%)
- 2025-01-22: 4교시 (82.0%), 5교시 (85.0%), 6교시 (88.0%)
- 2025-01-29: 1교시 (88.0%), 2교시 (80.0%)

**성취기준 판정 결과**:
- 1교시 (알파벳): 정확도 86.5%, 절대 기준 달성 (70% 이상), Z-score 0.8, 성취기준 도달
- 2교시 (음소 분리): 정확도 75.0%, 절대 기준 달성, Z-score -0.5, 성취기준 도달
- 3교시 (강세/리듬): 정확도 70.0%, 절대 기준 달성, Z-score -1.2, 성취기준 미도달 (통계적 기준 미달)
- 4교시 (파닉스): 정확도 82.0%, 절대 기준 달성, Z-score 0.5, 성취기준 도달
- 5교시 (어휘): 정확도 85.0%, 절대 기준 달성, Z-score 0.7, 성취기준 도달
- 6교시 (이해력): 정확도 88.0%, 절대 기준 달성, Z-score 1.0, 성취기준 도달
- 종합: 6개 영역 중 5개 영역 도달 (83.3%)

**교사의 활용**:
- 음소 분리와 강세/리듬 영역의 약점을 파악하여 개별 보충 지도 계획 수립
- 이해력 영역의 강점을 활용한 읽기 지도 전략 수립
- 학부모 상담 시 시각화 차트와 AI 코멘트를 활용한 구체적인 설명
- 성취기준 미도달 영역(3교시)에 대한 집중 지도 계획 수립

**전사 정확도 검토 예시**:

담임교사가 1교시 평가 결과 100개를 검토한 결과:

**리뷰 유형별 분포**:
- 유형 1 (정답 발화 → 정확한 전사 → 정답): 65개 (65%)
- 유형 2 (정답 발화 → 정확한 전사 → 오답): 5개 (5%)
- 유형 3 (정답 발화 → 부정확한 전사 → 정답): 8개 (8%)
- 유형 4 (정답 발화 → 부정확한 전사 → 오답): 12개 (12%)
- 유형 5 (오답 발화 → 정확한 전사 → 정답): 2개 (2%)
- 유형 6 (오답 발화 → 정확한 전사 → 오답): 3개 (3%)
- 기타 유형: 5개 (5%)

**통계 지표**:
- 음성 인식 정확도: 75% (유형 1,2,5,6 합계: 75개)
- 채점 정확도: 80% (유형 1,3,5,7,9,11,13 합계: 80개)

**인사이트**:
- 음성 인식 정확도가 75%로 개선 여지가 있음
- 부정확한 전사로 인한 오채점이 12% 발생 (유형 4)
- 채점 로직은 전반적으로 정확하게 작동하고 있음 (80%)
- 발화 수정 사례가 일부 발견되어 학생의 자기 수정 능력을 확인 가능

---

## 결론

본 플랫폼은 국가기초학력지원센터의 최소 성취기준을 바탕으로 AI 기술을 활용한 영어 읽기 능력 진단 평가 시스템을 구축하였습니다. 6가지 평가 유형을 통해 학생들의 알파벳 인식부터 이해력까지 단계적으로 평가하며, AI 기반 자동 채점으로 평가 시간을 대폭 단축하고 객관적인 평가 결과를 제공합니다.

교사 대시보드를 통해 학생들의 학습 진도를 체계적으로 관리하고, 시각화 차트와 AI 코멘트를 활용하여 맞춤형 지도가 가능합니다. 

### 성취기준 도달 판정 시스템의 교육적 의미

성취기준 도달 판정 시스템은 절대 기준과 통계적 기준을 모두 고려하여 학생의 성취 수준을 객관적으로 판정합니다. 이를 통해:

- **정확한 성취 수준 파악**: 단순 정확도가 아닌 반 전체 수준과 비교한 상대적 위치를 파악할 수 있습니다.
- **맞춤형 지도 계획 수립**: 성취기준 미도달 영역을 정확히 파악하여 집중 보충 지도가 가능합니다.
- **교육과정 연계**: 국가기초학력지원센터의 최소 성취기준과 직접 연계하여 교육과정 이수 여부를 확인할 수 있습니다.

### 전사 정확도 검토 시스템의 품질 관리 역할

전사 정확도 검토 시스템은 AI 시스템의 품질을 지속적으로 모니터링하고 개선하는 핵심 도구입니다:

- **시스템 정확도 모니터링**: 음성 인식 및 채점 정확도를 실시간으로 추적하여 시스템 품질을 관리합니다.
- **데이터 기반 개선**: 수집된 리뷰 데이터를 분석하여 AI 시스템의 약점을 파악하고 개선 방향을 제시합니다.
- **신뢰성 확보**: 교사의 검토를 통해 AI 시스템의 신뢰성을 검증하고, 오채점 사례를 분석하여 시스템을 개선합니다.

### 향후 발전 방향

- **실시간 성취기준 모니터링**: 학생의 평가 결과가 입력될 때마다 자동으로 성취기준 도달 여부를 업데이트
- **예측 분석**: 과거 평가 데이터를 기반으로 학생의 향후 성취 수준을 예측
- **자동 개선 시스템**: 전사 정확도 검토 데이터를 활용하여 AI 채점 로직을 자동으로 개선
- **학부모 포털**: 학부모가 자녀의 성취기준 도달 여부를 확인할 수 있는 포털 제공

향후 지속적인 기능 개선과 사용자 피드백 반영을 통해 더욱 효과적인 평가 플랫폼으로 발전시켜 나갈 예정입니다.

---

**참고문헌**

- 국가기초학력지원센터, "초등학교 3~4학년군 영어과 최소한의 성취기준"
- OpenAI, "Whisper API Documentation"
- OpenAI, "GPT-4o API Documentation"
- Supabase, "PostgreSQL Documentation"
- Next.js, "Next.js 15 Documentation"

